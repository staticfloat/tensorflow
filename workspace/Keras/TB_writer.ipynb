{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TB_writer(keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir='/data/tensorflow/logs',\n",
    "                 histogram_freq=0,\n",
    "                 batch_size=32,\n",
    "                 write_graph=True,\n",
    "                 write_grads=True,\n",
    "                 write_images=False,\n",
    "                 val_gen=None):\n",
    "        super(TB_writer, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.historgram_freq = historgram_freq\n",
    "        self.write_graph = write_graph\n",
    "        self.write_grads = write_grads\n",
    "        self.write_images = write_images\n",
    "        self.batch_size = batch_size\n",
    "        self.merged = None\n",
    "        self.val_gen = val_gen\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        if self.historgram_freq and self.merged is None:\n",
    "            for layer in self.model.layers:\n",
    "                for weight in layer.weights:\n",
    "                    mapped_weight_name = weight.name.replace(':', '_')\n",
    "                    tf.summary.histogram(mapped_weight_name, weight)\n",
    "                    \n",
    "                    if self.write_grads:\n",
    "                        grads = model.optimizer.get_gradients(model.total_loss, weight)\n",
    "                        tf.summary.histogram('{}_grad'.format(mapped_weight_name), grads)\n",
    "                        \n",
    "                    if self.write_images:\n",
    "                        w_img = tf.squeeze(weight)\n",
    "                        shape = K.int_shape(w_img)\n",
    "                        if len(shape)==2: #dense layer\n",
    "                            if shape[0] > shape[1]:\n",
    "                                w_img = tf.transpose(w_img)\n",
    "                                shape = K.int_shape(w_img)\n",
    "                            w_img = tf.reshape(w_img, [1, shape[0], shape[1], 1])\n",
    "                        elif len(shape == 3): #convnet check\n",
    "                            if K.image_data_format() == 'channels_last':\n",
    "                                w_img = tf.transpose(w_img, perm[2, 0, 1])\n",
    "                                shape = K.int_shape(w_img)\n",
    "                            w_img = tf.reshape(w_img [shape[0], shape[1], shape[2], 1])\n",
    "                        elif len(shape)==1: #bias case\n",
    "                            w_img = tf.reshape(w_img, [1, shape[0], 1, 1])\n",
    "                        else:\n",
    "                            # maybe cant handle 3d convnnets\n",
    "                            continue\n",
    "                        shape = K.int_shape(w_img)\n",
    "                        assert len(shape == 4 and shape[-1] in [1, 3, 4])\n",
    "                        tf.summary.image(mapped_weight_name,w_img)\n",
    "                        \n",
    "                if hasattr(layer, 'output'):\n",
    "                    tf.summary.historgram('{}_out'.format(layer.name), layer.output)\n",
    "                    \n",
    "            self.merged = tf.summary.merge_all()\n",
    "            if self.write_graph:\n",
    "                self.writer = tf.summary.FileWriter(self.log_dir, self.sess.graph)\n",
    "            else:\n",
    "                self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "                \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self.val_gen and self.histogram_freq:\n",
    "            if epoch % self.histogram_freq == 0:\n",
    "                val_data = self.val_gen.next()\n",
    "                tensors = (self.model.inputs +\n",
    "                           self.model.targets)\n",
    "\n",
    "                if self.model.uses_learning_phase:\n",
    "                    tensors += [K.learning_phase()]\n",
    "\n",
    "                assert len(val_data) == len(tensors)\n",
    "                val_size = val_data[0].shape[0]\n",
    "                i = 0\n",
    "                while i < val_size:\n",
    "                    step = min(self.batch_size, val_size - i)\n",
    "                    batch_val = []\n",
    "                    batch_val.append(val_data[0][i:i + step])\n",
    "                    batch_val.append(val_data[1][i:i + step])\n",
    "                    if self.model.uses_learning_phase:\n",
    "                        batch_val.append(val_data[2])\n",
    "                    feed_dict = dict(zip(tensors, batch_val))\n",
    "                    result = self.sess.run([self.merged], feed_dict=feed_dict)\n",
    "                    summary_str = result[0]\n",
    "                    self.writer.add_summary(summary_str, epoch)\n",
    "                    i += self.batch_size\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'set_model',\n",
       " 'set_params']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.callbacks.Callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
