{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Input\n",
    "from keras import backend as K\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def put_kernels_on_grid (kernel, pad = 1):\n",
    "\n",
    "  '''Visualize conv. filters as an image (mostly for the 1st layer).\n",
    "  Arranges filters into a grid, with some paddings between adjacent filters.\n",
    "  Args:\n",
    "    kernel:            tensor of shape [Y, X, NumChannels, NumKernels]\n",
    "    pad:               number of black pixels around each filter (between them)\n",
    "  Return:\n",
    "    Tensor of shape [1, (Y+2*pad)*grid_Y, (X+2*pad)*grid_X, NumChannels].\n",
    "  '''\n",
    "  # get shape of the grid. NumKernels == grid_Y * grid_X\n",
    "  def factorization(n):\n",
    "    for i in range(int(sqrt(float(n))), 0, -1):\n",
    "      if n % i == 0:\n",
    "        if i == 1: print('Who would enter a prime number of filters')\n",
    "        return (i, int(n / i))\n",
    "  (grid_Y, grid_X) = factorization (kernel.get_shape()[3].value)\n",
    "  print ('grid: %d = (%d, %d)' % (kernel.get_shape()[3].value, grid_Y, grid_X))\n",
    "\n",
    "  x_min = tf.reduce_min(kernel)\n",
    "  x_max = tf.reduce_max(kernel)\n",
    "  kernel = (kernel - x_min) / (x_max - x_min)\n",
    "\n",
    "  # pad X and Y\n",
    "  x = tf.pad(kernel, tf.constant( [[pad,pad],[pad, pad],[0,0],[0,0]] ), mode = 'CONSTANT')\n",
    "\n",
    "  # X and Y dimensions, w.r.t. padding\n",
    "  Y = kernel.get_shape()[0] + 2 * pad\n",
    "  X = kernel.get_shape()[1] + 2 * pad\n",
    "\n",
    "  channels = kernel.get_shape()[2]\n",
    "\n",
    "  # put NumKernels to the 1st dimension\n",
    "  x = tf.transpose(x, (3, 0, 1, 2))\n",
    "  # organize grid on Y axis\n",
    "  x = tf.reshape(x, tf.stack([grid_X, Y * grid_Y, X, channels]))\n",
    "\n",
    "  # switch X and Y axes\n",
    "  x = tf.transpose(x, (0, 2, 1, 3))\n",
    "  # organize grid on X axis\n",
    "  x = tf.reshape(x, tf.stack([1, X * grid_X, Y * grid_Y, channels]))\n",
    "\n",
    "  # back to normal order (not combining with the next step for clarity)\n",
    "  x = tf.transpose(x, (2, 1, 3, 0))\n",
    "\n",
    "  # to tf.image_summary order [batch_size, height, width, channels],\n",
    "  #   where in this case batch_size == 1\n",
    "  x = tf.transpose(x, (3, 0, 1, 2))\n",
    "\n",
    "  # scaling to [0, 255] is not necessary for tensorboard\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TB_writer(keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir=\"\",\n",
    "                 histogram_freq=0,\n",
    "                 batch_size=32,\n",
    "                 write_graph=True,\n",
    "                 write_grads=True,\n",
    "                 write_images=False,\n",
    "                 embeddings_freq=0,\n",
    "                 embeddings_layer_names=None,\n",
    "                 embeddings_metadata=None,\n",
    "                 val_gen=None):\n",
    "        super(TB_writer, self).__init__()\n",
    "        self.log_dir = \"/data/tensorflow/log/\"+log_dir\n",
    "        self.histogram_freq = histogram_freq\n",
    "        self.write_graph = write_graph\n",
    "        self.write_grads = write_grads\n",
    "        self.write_images = write_images\n",
    "        self.batch_size = batch_size\n",
    "        self.merged = None\n",
    "        self.val_gen = val_gen\n",
    "        self.embeddings_freq = embeddings_freq\n",
    "        self.embeddings_layer_names = embeddings_layer_names\n",
    "        self.embeddings_metadata = embeddings_metadata or {}\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        if self.histogram_freq and self.merged is None:\n",
    "            for layer in self.model.layers:\n",
    "                for weight in layer.weights:\n",
    "                    mapped_weight_name = weight.name.replace(':', '_')\n",
    "                    tf.summary.histogram(mapped_weight_name, weight)\n",
    "                    \n",
    "                    if self.write_grads:\n",
    "                        grads = model.optimizer.get_gradients(model.total_loss, weight)\n",
    "                        tf.summary.histogram('{}_grad'.format(mapped_weight_name), grads)\n",
    "                        \n",
    "                    if self.write_images:\n",
    "                        w_img = tf.squeeze(weight)\n",
    "                        shape = K.int_shape(w_img)\n",
    "                        if len(shape)==2: #dense layer\n",
    "                            if shape[0] > shape[1]:\n",
    "                                w_img = tf.transpose(w_img)\n",
    "                                shape = K.int_shape(w_img)\n",
    "                            w_img = tf.reshape(w_img, [1, shape[0], shape[1], 1])\n",
    "                            w_img = tf.transpose(w_img)\n",
    "                        elif len(shape) == 4: #convnet check\n",
    "                            w_img = put_kernels_on_grid(w_img)\n",
    "                            #if K.image_data_format() == 'channels_last':\n",
    "                            #    #w_img = tf.transpose(w_img, perm[2, 0, 1])\n",
    "                            #    w_img = tf.transpose(w_img, perm=[3, 2, 0, 1])\n",
    "                            #    shape = K.int_shape(w_img)\n",
    "                            # break kernel into black and white per channel\n",
    "                            #imgs = tf.split(w_img)                            \n",
    "                            #w_img = tf.reshape(w_img [shape[0], shape[1], shape[2], 1])\n",
    "                            w_img = tf.transpose(w_img, perm=[3, 1, 2, 0])\n",
    "                        elif len(shape)==1: #bias case\n",
    "                            w_img = tf.reshape(w_img, [1, shape[0], 1, 1])\n",
    "                            w_img = tf.transpose(w_img)\n",
    "                        else:\n",
    "                            # maybe cant handle 3d convnnets\n",
    "                            continue\n",
    "                        shape = K.int_shape(w_img)\n",
    "                        #print(shape)\n",
    "                        assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n",
    "                        tf.summary.image(mapped_weight_name,w_img, max_outputs=32)\n",
    "                        \n",
    "                if hasattr(layer, 'output'):\n",
    "                    tf.summary.histogram('{}_out'.format(layer.name), layer.output)\n",
    "                    \n",
    "            self.merged = tf.summary.merge_all()\n",
    "            if self.write_graph:\n",
    "                self.writer = tf.summary.FileWriter(self.log_dir, self.sess.graph)\n",
    "            else:\n",
    "                self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "                \n",
    "            if self.embeddings_freq:\n",
    "                embeddings_layer_names = self.embeddings_layer_names\n",
    "\n",
    "                if not embeddings_layer_names:\n",
    "                    embeddings_layer_names = [layer.name for layer in self.model.layers\n",
    "                                              if type(layer).__name__ == 'Embedding']\n",
    "\n",
    "                embeddings = {layer.name: layer.weights[0]\n",
    "                              for layer in self.model.layers\n",
    "                              if layer.name in embeddings_layer_names}\n",
    "\n",
    "                self.saver = tf.train.Saver(list(embeddings.values()))\n",
    "\n",
    "                embeddings_metadata = {}\n",
    "\n",
    "                if not isinstance(self.embeddings_metadata, str):\n",
    "                    embeddings_metadata = self.embeddings_metadata\n",
    "                else:\n",
    "                    embeddings_metadata = {layer_name: self.embeddings_metadata\n",
    "                                           for layer_name in embeddings.keys()}\n",
    "\n",
    "                config = projector.ProjectorConfig()\n",
    "                self.embeddings_ckpt_path = os.path.join(self.log_dir,\n",
    "                                                         'keras_embedding.ckpt')\n",
    "\n",
    "                for layer_name, tensor in embeddings.items():\n",
    "                    embedding = config.embeddings.add()\n",
    "                    embedding.tensor_name = tensor.name\n",
    "\n",
    "                    if layer_name in embeddings_metadata:\n",
    "                        embedding.metadata_path = embeddings_metadata[layer_name]\n",
    "\n",
    "                projector.visualize_embeddings(self.writer, config)\n",
    "                \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self.val_gen and self.histogram_freq:\n",
    "            if epoch % self.histogram_freq == 0:\n",
    "                val_data = self.val_gen.next() + ([1], )\n",
    "                tensors = (self.model.inputs +\n",
    "                           self.model.targets +\n",
    "                           self.model.sample_weights)\n",
    "                \n",
    "                if self.model.uses_learning_phase:\n",
    "                    tensors += [K.learning_phase()]\n",
    "                    val_data += ((True, ))                  \n",
    "\n",
    "                assert len(val_data) == len(tensors)\n",
    "                val_size = val_data[0].shape[0]\n",
    "                i = 0\n",
    "                while i < val_size:\n",
    "                    step = min(self.batch_size, val_size - i)\n",
    "                    batch_val = []\n",
    "                    batch_val.append(val_data[0][i:i + step])\n",
    "                    batch_val.append(val_data[1][i:i + step])\n",
    "                    batch_val.append(val_data[2])\n",
    "                    if self.model.uses_learning_phase:\n",
    "                        batch_val.append(val_data[3])\n",
    "                    feed_dict = dict(zip(tensors, batch_val))\n",
    "                    result = self.sess.run([self.merged], feed_dict=feed_dict)\n",
    "                    summary_str = result[0]\n",
    "                    self.writer.add_summary(summary_str, epoch)\n",
    "                    i += self.batch_size\n",
    "                    \n",
    "        if self.embeddings_freq and self.embeddings_ckpt_path:\n",
    "            if epoch % self.embeddings_freq == 0:\n",
    "                self.saver.save(self.sess,\n",
    "                                self.embeddings_ckpt_path,\n",
    "                                epoch)\n",
    "                \n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/data/cifar/train/',\n",
    "        target_size=(32,32),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/data/cifar/test/',\n",
    "        target_size=(32,32),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(32,32,3))\n",
    "z = Convolution2D(32, (3,3), activation='relu')(inp)\n",
    "z = Convolution2D(32, (3,3), activation='relu')(z)\n",
    "z = MaxPooling2D(pool_size=(2,2))(z)\n",
    "z = Dropout(0.25)(z)\n",
    "\n",
    "z = Flatten()(z)\n",
    "z = Dense(128, activation='relu')(z)\n",
    "z = Dropout(0.5)(z)\n",
    "z = Dense(10, activation='softmax')(z)\n",
    "\n",
    "model = Model(inputs=inp, outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 814,378\n",
      "Trainable params: 814,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid: 32 = (4, 8)\n",
      "grid: 32 = (4, 8)\n"
     ]
    }
   ],
   "source": [
    "#tb_callback = keras.callbacks.TensorBoard(log_dir='/data/tensorflow/log/cifar_test', histogram_freq=1, write_images=True, write_grads=True)\n",
    "#tb_callback.set_model(model)\n",
    "tb_callback = TB_writer(histogram_freq=1, write_images=True, log_dir=\"cifar_test\", val_gen=validation_generator)\n",
    "tb_callback.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s - loss: 2.1853 - acc: 0.1772 - val_loss: 1.9637 - val_acc: 0.2963\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 2s - loss: 1.9761 - acc: 0.2753 - val_loss: 1.7602 - val_acc: 0.3916\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 2s - loss: 1.8220 - acc: 0.3259 - val_loss: 1.6363 - val_acc: 0.4169\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 2s - loss: 1.7932 - acc: 0.3506 - val_loss: 1.5627 - val_acc: 0.4391\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 2s - loss: 1.7378 - acc: 0.3650 - val_loss: 1.5790 - val_acc: 0.4487\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 2s - loss: 1.6877 - acc: 0.3775 - val_loss: 1.5999 - val_acc: 0.4369\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 2s - loss: 1.6582 - acc: 0.4034 - val_loss: 1.4618 - val_acc: 0.4834\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 2s - loss: 1.6444 - acc: 0.4037 - val_loss: 1.4739 - val_acc: 0.4741\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 2s - loss: 1.6075 - acc: 0.4200 - val_loss: 1.3543 - val_acc: 0.5134\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 2s - loss: 1.5910 - acc: 0.4200 - val_loss: 1.3896 - val_acc: 0.4843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde603bd650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=100,\n",
    "        callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image( infilename ) :\n",
    "    img = Image.open( infilename )\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"float32\" )\n",
    "    data = data/255\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = load_image(\"/data/cifar/test/truck/1008_truck.png\")\n",
    "image = image.reshape((1,)+image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_map =validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guess = np.argmax(model.predict(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_labels=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_labels[guess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
