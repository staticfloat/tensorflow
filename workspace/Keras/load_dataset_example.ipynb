{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Input, BatchNormalization, AveragePooling2D, Reshape, Activation\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import backend as K\n",
    "from math import sqrt\n",
    "import sys\n",
    "sys.path.append('../CustomLayers/')\n",
    "from CustomLayers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def put_kernels_on_grid (kernel, pad = 1):\n",
    "\n",
    "  '''Visualize conv. filters as an image (mostly for the 1st layer).\n",
    "  Arranges filters into a grid, with some paddings between adjacent filters.\n",
    "  Args:\n",
    "    kernel:            tensor of shape [Y, X, NumChannels, NumKernels]\n",
    "    pad:               number of black pixels around each filter (between them)\n",
    "  Return:\n",
    "    Tensor of shape [1, (Y+2*pad)*grid_Y, (X+2*pad)*grid_X, NumChannels].\n",
    "  '''\n",
    "  # get shape of the grid. NumKernels == grid_Y * grid_X\n",
    "  def factorization(n):\n",
    "    for i in range(int(sqrt(float(n))), 0, -1):\n",
    "      if n % i == 0:\n",
    "        if i == 1: print('Who would enter a prime number of filters')\n",
    "        return (i, int(n / i))\n",
    "  (grid_Y, grid_X) = factorization (kernel.get_shape()[3].value)\n",
    "  #print ('grid: %d = (%d, %d)' % (kernel.get_shape()[3].value, grid_Y, grid_X))\n",
    "\n",
    "  x_min = tf.reduce_min(kernel)\n",
    "  x_max = tf.reduce_max(kernel)\n",
    "  kernel = (kernel - x_min) / (x_max - x_min)\n",
    "\n",
    "  # pad X and Y\n",
    "  x = tf.pad(kernel, tf.constant( [[pad,pad],[pad, pad],[0,0],[0,0]] ), mode = 'CONSTANT')\n",
    "\n",
    "  # X and Y dimensions, w.r.t. padding\n",
    "  Y = kernel.get_shape()[0] + 2 * pad\n",
    "  X = kernel.get_shape()[1] + 2 * pad\n",
    "\n",
    "  channels = kernel.get_shape()[2]\n",
    "\n",
    "  # put NumKernels to the 1st dimension\n",
    "  x = tf.transpose(x, (3, 0, 1, 2))\n",
    "  # organize grid on Y axis\n",
    "  x = tf.reshape(x, tf.stack([grid_X, Y * grid_Y, X, channels]))\n",
    "\n",
    "  # switch X and Y axes\n",
    "  x = tf.transpose(x, (0, 2, 1, 3))\n",
    "  # organize grid on X axis\n",
    "  x = tf.reshape(x, tf.stack([1, X * grid_X, Y * grid_Y, channels]))\n",
    "\n",
    "  # back to normal order (not combining with the next step for clarity)\n",
    "  x = tf.transpose(x, (2, 1, 3, 0))\n",
    "\n",
    "  # to tf.image_summary order [batch_size, height, width, channels],\n",
    "  #   where in this case batch_size == 1\n",
    "  x = tf.transpose(x, (3, 0, 1, 2))\n",
    "\n",
    "  # scaling to [0, 255] is not necessary for tensorboard\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TB_writer(keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir=\"\",\n",
    "                 histogram_freq=0,\n",
    "                 batch_size=32,\n",
    "                 write_graph=True,\n",
    "                 write_grads=True,\n",
    "                 write_images=False,\n",
    "                 embeddings_freq=0,\n",
    "                 embeddings_layer_names=None,\n",
    "                 embeddings_metadata=None,\n",
    "                 val_gen=None):\n",
    "        super(TB_writer, self).__init__()\n",
    "        self.log_dir = \"/data/tensorflow/log/\"+log_dir\n",
    "        self.histogram_freq = histogram_freq\n",
    "        self.write_graph = write_graph\n",
    "        self.write_grads = write_grads\n",
    "        self.write_images = write_images\n",
    "        self.batch_size = batch_size\n",
    "        self.merged = None\n",
    "        self.val_gen = val_gen\n",
    "        self.embeddings_freq = embeddings_freq\n",
    "        self.embeddings_layer_names = embeddings_layer_names\n",
    "        self.embeddings_metadata = embeddings_metadata or {}\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        if self.histogram_freq and self.merged is None:\n",
    "            for layer in self.model.layers:\n",
    "                for weight in layer.weights:\n",
    "                    mapped_weight_name = weight.name.replace(':', '_')\n",
    "                    if len(weight.shape) == 4:\n",
    "                        kernel_split = tf.split(weight, weight.shape[3], axis=3)\n",
    "                        i = 0\n",
    "                        for kernel in kernel_split:\n",
    "                            tf.summary.histogram(mapped_weight_name + str(i), kernel)\n",
    "                            i += 1\n",
    "                    else:\n",
    "                        tf.summary.histogram(mapped_weight_name, weight)\n",
    "                    \n",
    "                    if self.write_grads:\n",
    "                        grads = model.optimizer.get_gradients(model.total_loss, weight)\n",
    "                        tf.summary.histogram('{}_grad'.format(mapped_weight_name), grads)\n",
    "                        \n",
    "                    if self.write_images:\n",
    "                        w_img = tf.squeeze(weight)\n",
    "                        shape = K.int_shape(w_img)\n",
    "                        if len(shape)==2: #dense layer\n",
    "                            if shape[0] > shape[1]:\n",
    "                                w_img = tf.transpose(w_img)\n",
    "                                shape = K.int_shape(w_img)\n",
    "                            w_img = tf.reshape(w_img, [1, shape[0], shape[1], 1])\n",
    "                            w_img = tf.transpose(w_img)\n",
    "                        elif len(shape) == 4: #convnet check\n",
    "                            w_img = put_kernels_on_grid(w_img)\n",
    "                            #if K.image_data_format() == 'channels_last':\n",
    "                            #    #w_img = tf.transpose(w_img, perm[2, 0, 1])\n",
    "                            #    w_img = tf.transpose(w_img, perm=[3, 2, 0, 1])\n",
    "                            #    shape = K.int_shape(w_img)\n",
    "                            # break kernel into black and white per channel\n",
    "                            #imgs = tf.split(w_img)                            \n",
    "                            #w_img = tf.reshape(w_img [shape[0], shape[1], shape[2], 1])\n",
    "                            w_img = tf.transpose(w_img, perm=[3, 1, 2, 0])\n",
    "                        elif len(shape)==1: #bias case\n",
    "                            w_img = tf.reshape(w_img, [1, shape[0], 1, 1])\n",
    "                            w_img = tf.transpose(w_img)\n",
    "                        else:\n",
    "                            # maybe cant handle 3d convnnets\n",
    "                            continue\n",
    "                        shape = K.int_shape(w_img)\n",
    "                        #print(shape)\n",
    "                        assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n",
    "                        tf.summary.image(mapped_weight_name,w_img, max_outputs=8)\n",
    "                        \n",
    "                if hasattr(layer, 'output'):              \n",
    "                    mapped_layer_name = layer.name.replace(':', '_')\n",
    "                    if len(layer.output.shape) == 4:                        \n",
    "                        output_split = tf.split(layer.output, layer.output.shape[3], axis=3)\n",
    "                        i = 0\n",
    "                        for output in output_split:\n",
    "                            tf.summary.histogram('{}/out'.format(mapped_layer_name) + str(i), output)\n",
    "                            tf.summary.image('{}/out'.format(mapped_layer_name) + str(i), output)\n",
    "                            i += 1\n",
    "                            if i > 16:\n",
    "                                break;\n",
    "                    else:\n",
    "                        tf.summary.histogram('{}/out'.format(mapped_layer_name), layer.output)                        \n",
    "                    \n",
    "            self.merged = tf.summary.merge_all()\n",
    "            if self.write_graph:\n",
    "                self.writer = tf.summary.FileWriter(self.log_dir, self.sess.graph)\n",
    "            else:\n",
    "                self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "                \n",
    "            if self.embeddings_freq:\n",
    "                embeddings_layer_names = self.embeddings_layer_names\n",
    "\n",
    "                if not embeddings_layer_names:\n",
    "                    embeddings_layer_names = [layer.name for layer in self.model.layers\n",
    "                                              if type(layer).__name__ == 'Embedding']\n",
    "\n",
    "                embeddings = {layer.name: layer.weights[0]\n",
    "                              for layer in self.model.layers\n",
    "                              if layer.name in embeddings_layer_names}\n",
    "\n",
    "                self.saver = tf.train.Saver(list(embeddings.values()))\n",
    "\n",
    "                embeddings_metadata = {}\n",
    "\n",
    "                if not isinstance(self.embeddings_metadata, str):\n",
    "                    embeddings_metadata = self.embeddings_metadata\n",
    "                else:\n",
    "                    embeddings_metadata = {layer_name: self.embeddings_metadata\n",
    "                                           for layer_name in embeddings.keys()}\n",
    "\n",
    "                config = projector.ProjectorConfig()\n",
    "                self.embeddings_ckpt_path = os.path.join(self.log_dir,\n",
    "                                                         'keras_embedding.ckpt')\n",
    "\n",
    "                for layer_name, tensor in embeddings.items():\n",
    "                    embedding = config.embeddings.add()\n",
    "                    embedding.tensor_name = tensor.name\n",
    "\n",
    "                    if layer_name in embeddings_metadata:\n",
    "                        embedding.metadata_path = embeddings_metadata[layer_name]\n",
    "\n",
    "                projector.visualize_embeddings(self.writer, config)\n",
    "                \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self.val_gen and self.histogram_freq:\n",
    "            if epoch % self.histogram_freq == 0:\n",
    "                val_data = self.val_gen.next() + ([1], )\n",
    "                tensors = (self.model.inputs +\n",
    "                           self.model.targets +\n",
    "                           self.model.sample_weights)\n",
    "                \n",
    "                if self.model.uses_learning_phase:\n",
    "                    tensors += [K.learning_phase()]\n",
    "                    val_data += ((True, ))                  \n",
    "\n",
    "                assert len(val_data) == len(tensors)\n",
    "                val_size = val_data[0].shape[0]\n",
    "                i = 0\n",
    "                while i < val_size:\n",
    "                    step = min(self.batch_size, val_size - i)\n",
    "                    batch_val = []\n",
    "                    batch_val.append(val_data[0][i:i + step])\n",
    "                    batch_val.append(val_data[1][i:i + step])\n",
    "                    batch_val.append(val_data[2])\n",
    "                    if self.model.uses_learning_phase:\n",
    "                        batch_val.append(val_data[3])\n",
    "                    feed_dict = dict(zip(tensors, batch_val))\n",
    "                    result = self.sess.run([self.merged], feed_dict=feed_dict)\n",
    "                    summary_str = result[0]\n",
    "                    self.writer.add_summary(summary_str, epoch)\n",
    "                    i += self.batch_size\n",
    "                    \n",
    "        if self.embeddings_freq and self.embeddings_ckpt_path:\n",
    "            if epoch % self.embeddings_freq == 0:\n",
    "                self.saver.save(self.sess,\n",
    "                                self.embeddings_ckpt_path,\n",
    "                                epoch)\n",
    "                \n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/data/cifar/train/',\n",
    "        target_size=(32,32),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/data/cifar/test/',\n",
    "        target_size=(32,32),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 32\n",
    "img_h = 32\n",
    "img_c = 3\n",
    "inp = Input(shape=(img_w, img_h, img_c))\n",
    "\n",
    "z = Convolution2D(32, (3,3), activation='relu')(inp)\n",
    "z = MaxPooling2D(pool_size=(3,3), strides=(2,2))(z)\n",
    "\n",
    "z = BatchNormalization()(z)\n",
    "#z = Convolution2D(32, (3,3), activation='relu')(z)\n",
    "#z = BinLayer()(z)\n",
    "z = MultibitLayer(3)(z)\n",
    "z = BinConv(128, (3,3), kernel_regularizer=BinReg(), padding='same')(z)\n",
    "z = PReLU()(z)\n",
    "z = MaxPooling2D(pool_size=(3,3), strides=(2,2))(z)\n",
    "\n",
    "z = BatchNormalization()(z)\n",
    "#z = BinLayer()(z)\n",
    "z = MultibitLayer(3)(z)\n",
    "z = BinConv(128, (3,3), kernel_regularizer=BinReg(), padding='same')(z)\n",
    "z = PReLU()(z)\n",
    "z = MaxPooling2D(pool_size=(3,3), strides=(2,2))(z)\n",
    "\n",
    "z = BatchNormalization()(z)\n",
    "z = Convolution2D(10, (1,1), activation='relu')(z)\n",
    "z = AveragePooling2D(pool_size=(int(z.shape[1]), int(z.shape[2])))(z)\n",
    "z = Reshape((10,))(z)\n",
    "z = Activation('softmax')(z)\n",
    "\n",
    "model = Model(inputs=inp, outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "multibit_layer_1 (MultibitLa (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "bin_conv_1 (BinConv)         (None, 14, 14, 128)       36992     \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 14, 14, 128)       25088     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "multibit_layer_2 (MultibitLa (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "bin_conv_2 (BinConv)         (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 6, 6, 128)         4608      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 10)          1290      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 217,610\n",
      "Trainable params: 217,034\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = TB_writer(histogram_freq=1, write_images=True, log_dir=\"cifar_test_binary\", val_gen=validation_generator)\n",
    "tb_callback.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s - loss: 2.5142 - acc: 0.2972 - val_loss: 3.3439 - val_acc: 0.1862\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 2s - loss: 2.2553 - acc: 0.3991 - val_loss: 4.6993 - val_acc: 0.1775\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 2s - loss: 2.1618 - acc: 0.4309 - val_loss: 3.9613 - val_acc: 0.1609\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 2s - loss: 2.0620 - acc: 0.4731 - val_loss: 3.6179 - val_acc: 0.1643\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 2s - loss: 2.0338 - acc: 0.4756 - val_loss: 2.4319 - val_acc: 0.3647\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 2s - loss: 2.0175 - acc: 0.4869 - val_loss: 2.0824 - val_acc: 0.4500\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 2s - loss: 1.9792 - acc: 0.4934 - val_loss: 2.0066 - val_acc: 0.5006\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 2s - loss: 1.9498 - acc: 0.5147 - val_loss: 1.9076 - val_acc: 0.5066\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 2s - loss: 1.9145 - acc: 0.5325 - val_loss: 1.8711 - val_acc: 0.5353\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 2s - loss: 1.9430 - acc: 0.5075 - val_loss: 1.9880 - val_acc: 0.4937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bb121d710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=100,\n",
    "        callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image( infilename ) :\n",
    "    img = Image.open( infilename )\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"float32\" )\n",
    "    data = data/255\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = load_image(\"/data/cifar/test/truck/1008_truck.png\")\n",
    "image = image.reshape((1,)+image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_map =validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guess = np.argmax(model.predict(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_labels=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_labels[guess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
